Vocab
============

在文本分类过程中，词是我们最开始的特征，之后可能把词转化为词频，TFIDF值，词向量等。

统计机器学习让模型自动学习出词feature与label的相关性。但是这其中有许多一部分是不对的！
对的意思是，词feature在真正意义上（基于语义的，语用的）与label的相关性，但是统计机器学习至少现在这些Task-based
机器学习会学习出许多偏置。一般的语料都会有各种各样不需要的偏置，好的语料偏置会少一些。

以情感分析为例，我们首先收集均衡的语料，用cnn训练。
训练后，每个词会被cnn分为正的或者负的。实际上，有一部分是极性词，即我们需要的，其他的是非极性词，是并
不需要的。所以我期望在模型预测前置一个模型相关的词典，把非极性词提前去掉。
词典维护这个模型所有需要的词与词的属性，以提供词典上的各种功能：比如极性/非极性过滤；语法加权；增量学习。


代码在$TEXTCLF/vocab

每个词有{setiment,flag,vector,index}的属性。
常用方法包括类初始化、文件读写、一致性地update。

用例包括情感新词发现的代码 
